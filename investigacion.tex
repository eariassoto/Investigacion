\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{makeidx}
\author{Arias E., Sagasti A.}
\date{\today}
\title{Tesla cantaba Kumbaya alrededor de su bobina}
\begin{document}
\begin{titlepage}
\maketitle
\end{titlepage}
\part{Conceptos Fundamentales}
\index{Conceptos Fundamentales}
En este capítulo vamos a desarrollar las bases necesarias para poder llegar a un pleno entendimiento de la investigación. Es una especie de marco teórico donde se abarcará la terminología básica de ciertos conceptos matemáticos y computacionales tratados en los siguientes capítulos. No debe entenderse como un glosario o un capítulo de definiciones sino que, este es el comienzo de la investigación en su etapa más básica.

\section*{Conceptos matemáticos}
Para poder comprender mejor los postulados de la Teoría Cuántica es necesario tener un conocimiento básico de álgebra lineal, específicamente sobre espacios vectoriales. Asumimos que el lector posee conocimientos sobre este tema, sin embargo vamos a hacer un pequeño repaso en conceptos fundamentales. 
Shankar (1994) define los espacios vectoriales como:

\begin{quote}
\textit{Un espacio vectorial lineal $\mathbb{V}$ es una colección de objetos} $\vert1\rangle,\vert2\rangle,...,\vert V\rangle,...,\vert W\rangle,...,$ llamados vectores, para los cuales existe
\\\\
1. Una regla definida para realizar la suma de vectores, denotada $\vert V\rangle+\vert W\rangle$
\\2. Una regla definida para la multiplicación por escalares \textit{a,b,...,} denotada $a\vert V\rangle$ con las siguientes características:
\\
\begin{itemize}
\item El resultado de estas operaciones resulta en otro elemento del espacio, una característica llamada \textit{cerrado}: $\vert V\rangle+ \vert W\rangle\in\mathbb{V}$.
\item La multiplicación por escalares es \textit{distributiva en los vectores}: $a(\vert V\rangle+\vert W\rangle)=a\vert V\rangle+a\vert W\rangle$.
\item La multiplicación por escalares es \textit{distributiva en los escalares}: $(a+b)\vert V\rangle=a\vert V\rangle+b\vert V\rangle$.
\item La multiplicación por escalares es \textit{asociativa}: $a(b\vert V\rangle)=ab\vert V\rangle$.
\item La suma es \textit{conmutativa}: $\vert V\rangle+\vert W\rangle=\vert W\rangle+\vert V\rangle$.
\item La suma es \textit{asociativa}: $\vert V\rangle+(\vert W\rangle+\vert Z\rangle)=(\vert V\rangle+\vert W\rangle)+\vert Z\rangle$.
\item Existe un \textit{vector nulo} $\vert 0\rangle$ que obedece $\vert V\rangle+\vert 0\rangle=\vert V\rangle$.
\item Para cada vector $\vert V\rangle$ existe un \textit{inverso respecto a la suma}, $\vert -V\rangle$, tal que $\vert V\rangle+\vert -V\rangle=\vert 0\rangle$. (p. 2)
\end{itemize}
\end{quote}

Esta notación de vectores $\vert V\rangle$ llamada \textit{notación Dirac} será muy utilizada más adelante cuando veamos los qubits, los cuales se rigen por las mismas reglas de espacios vectoriales mencionadas anteriormente. Además de estas reglas es necesario que consideremos los conceptos de \textit{campo}, \textit{combinaciones lineales} y \textit{bases ortonormales}.

Es importante que definamos el \textit{campo} de un espacio vectorial. El campo se refiere al espacio donde están definidos los escalares que multiplican al espacio vectorial. Como los vectores no son número en sí, estos no se pueden multiplicar. Entonces, para poder multiplicar vectores necesitamos usar escalar inscritos a un campo. Por ejemplo, un \textit{espacio vectorial real} es un espacio definido por escalares reales. De igual manera tenemos los \textit{espacios vectoriales complejos}, entre otros.

Debemos tener una noción básica de las combinaciones lineales en los espacios vectoriales. Como definición básica encontramos que Arce, Castillo y González (2003) explican que:
\begin{quote}
\textit{
Sea E un espacio vectorial y $\lbrace v_{1},v_{2},...,v_{p}\rbrace$, un conjunto de vectores de E. Se llama combinación lineal de los vectores $v_{1},v_{2},...,v_{p}$ al vector
\begin{center}
$v=a_{1}v_{1}+a_{2}v_{2}+\cdot\cdot\cdot+a_{p}v_{p}$
\end{center}
cualquiera sea la elección de los escalares $a_{1},a_{2},...,a_{p}$. Y al conjunto
\begin{center}
$\mathcal{C}\ell=\lbrace v_{1},...,v_{p}\rbrace = \lbrace a_{1}v_{1},a_{2}v_{2},...,a_{p}v_{p}\mid a_{1},a_{2},...,a_{p}\in\mathbb{R}\rbrace$
\end{center}
se le denomina conjunto de combinaciones lineales de $v_{1},v_{2},...,v_{p}$.(p. 221)
}
\end{quote}
Este concepto nos sirve además para comprender qué es una base. Se dice que:
\begin{quote}
\textit{Un conjunto de vectores $\lbrace v_{1},v_{2},..,v_{k}\rbrace$ de un espacio vectorial E, es una base de este espacio si y solo si todo vector $v \in E$ se puede expresar como combinación lineal \textbf{única} de los vectores $v_{1},v_{2},..,v_{k}$. (Arce et al., 2003, p. 226)
}
\end{quote}

Finalmente, para comprender el concepto de bases ortonormales necesitamos aclarar una operación de vectores y una característica de los mismos. Estas son el producto punto y la norma. El producto punto se define como:
\begin{quote}
\textit{
Sean $\vec{a}=(a_{1},a_{2},...,a_{n})^{t}$ y $\vec{b}=(b_{1},b_{2},...,b_{n})^{t}$. El producto escalar, o producto punto de $\vec{a}$ y $\vec{b}$ es un número real denotado y expresado en la siguiente forma:
\begin{center}
  $\vec{a}\cdot\vec{b}=a_{1}b_{1}+a_{2}b_{2}+\cdot\cdot\cdot+a_{n}b_{n}$ (Arce et al., 2003, p. 158)
\end{center}
}
\end{quote}
Es decir, si tenemos dos vectores podemos multiplicar las entradas de estos en orden y la suma de estos dará un número real, o complejo dependiendo del campo. Debemos anotar que esta es la notación ordinaria de vectores. En la notación Dirac si tenemos los vectores \textit{V} y \textit{W} el producto punto está denotado como $\langle V\vert W\rangle$. Dos vectores son \textit{ortogonales o perpendiculares} si y solo si $\langle V\vert W\rangle=0$.
Por otro lado, la norma de un vector, también conocida como magnitud, de una forma generalizada se define por: "$\sqrt{\langle V\vert V\rangle}\equiv\vert V \vert$ (...). Un \textit{vector normal} tiene una norma igual a uno." (Shankar, 1994, p. 9)

Ahora bien, aclarados esto términos podemos definir una \textit{base ortonormal} como: $"$Un conjunto de vectores base normales, los cuales son ortogonales dos a dos." (Shankar, 1994, p. 9).

\section*{Introducción a la Mecánica Cuántica}
En cuanto al concepto de Mecánica cuántica no discutiremos a profundidad los postulados que este propone, puesto que eso sería un enorme discusión. Sin embargo, vamos a comparar el primer postulado de la mecánica cuánticacon el primer postulado de la mecánica clásica. El primero afirma que: ''El estado de una partícula en algún momento dado está especificado por las variables \textit{x(t)} y \textit{p(t)}, i.e., como un punto en un espacio de dos dimensiones.'' (Shankar, 1994, p. 115). Mientras que el segundo dice que: ''El estado de una partícula está representado por el vector $\vert \psi(t)\rangle$ en un espacio Hilbert.'' (Shankar, 1994, p.115)

Con este postulado, podríamos decir que tenemos la base para comprender el concepto de los qubits. Pero en general, qué es la mecánica cuántica. Nielsen y Chuang (2010) la definen como: ''(...)un marco matemático o un conjunto de reglas para la construcción de teorías de la física.'' (p. 2). Nos parece contextualmente comprensible la analogía que plantean estos autores. En esta, comparan la relación que tiene la mecánica cuántica y las teorías que derivan de ella con un sistema operativo y sus aplicaciones de software (p. 2). Como vemos entre ambas relaciones hay una conexión de base, donde el primer concepto sirve de fundamento para que se creen los elementos con los cuales se relacionan.

Incluso yendo más allá de una simple definición y contexto histórico Nielsen y Chuang (2010) se atreven, luego de hacer una línea de tiempo en el desarrollo de la mecánica cuántica a proponerla como un reto para la computación. Ellos exponen los inicios de esta nueva forma de ver la física, que se remontan a las años 20 hasta los hallazgos más destacables que datan desde los años 70 hasta la actualidad. Luego, hace una reflexión acerca de que los intentos por desarrollar nuevos hallazgos científicados, aunque sea por mera corazonada, han dado nacimiento a importantes descubrimientos en la historia de la humanidad. Es aquí donde ellos recalcan que la computación e informática cuántica caben a la perfección en este esquema de resolver retos propuestos por nuevos esquemas de conocimiento. (pp. 2-3)

Entonces, el desarrollo de la mecánica cuántica en las ciencias de la computación puede representar un inmenso avance en el desarrollo de soluciones para los problemas propios de este ciencia. 

Para poner un ejemplo, vamos a retroceder un momento en historia y remontemos sobre los inicios de la computación. Si nos colocamos en los antecedentes de las primeras computadoras electrónicas tenemos el gran aporte de Alan Turing. Turing (1936) propone el concepto de una máquina que es capaz de interpretar un número finito de instrucciones llamadas "m-configurations". Esta máquina será alimentada por una cinta seccionada que va a contener el conjunto de instrucciones que se desean que la máquina interprete y como resultado imprimirá en otra cinta los resultados de las instrucciones que la máquina va a interpretar. (p. 232). Solo para recalcar la importancia del trabajo de Turing, Herken (1998) afirma que: ''Es bastante sorprendente ver cómo, en tan sólo diez años después de ''Computable Numbers'', había traducido sus ideas en una poderosa visión profética del potencial de la tecnología informática'' (p. 8) 

Pero volviendo a la línea histórica, tenemos el trabajo de Turing que mencionamos que data de 1936, luego tenemos a John Von Neumann. Los aportes que Von Neumann hizo al conocimiento científico en general son muchos y en diversas áreas (incluyendo en la mecánica cuántica) pero ahora nos limitaremos a su trabajo \textit{First Draft of a Report on the EDVAC}. Incluso siendo una borrador incompleto, muestra la arquitectura de la computadora EDVAC. Esta se convirtió en la arquitectura más usada en la creación de nuevas computadoras y como base se ha mantenido hasta la actualidad. Con la invención del transistor en 1947 el desarrollo de nuevo hardware se vió impulsado y esta arquitectura obtuvo mucha más fuerza.

Gracias a los transistores, se comenzó el desarrollo de circuitos integrados. El experto en fisicoquímica Gordon Moore (1965) habla sobre las ventajas y los posibles usos de los circuitos integrados. Inclusive afirma que: 
\begin{quote}
el futuro de la electrónica integrada es el futuro de la electrónica misma.(...)

La electrónica integrada hará las técnicas electrónicas más accesibles al resto de la sociedad, realizando muchas funciones que en el presente se hacen inadecuadamente o no se hacen del todo. La principal ventaja serán bajos costos y diseños grandemente simplificados---recompensa de un suministro de paquetes funcionales de bajo costo. (pp. 1-2)
\end{quote}
Sin embargo, él propone en este artículo una cierta preocupación. Moore (1965) espera que para la siguiente década se duplique el número de componentes en un circuito integrado. Esta aproximación resulto ser casi apegada a la realidad del futuro tanto que se le dió el nombre de \textit{Ley de Moore}.

Con esto ya expuesto podemos tener una aproximación del futuro en la construcción de computadores a nivel de hardware. El crecimiento acelerado de componentes va a llegar a un punto donde va a ser necesario buscar una solución. Es aquí donde Nielsen y Chuang (2010) proponen como solución buscar nuevos paradigmas computacionales, y uno de estos puede ser fruto de la teoría de la computación cuántica. Los autores hablan sobre computadoras que procesen información usando métodos de mecánica cuántica a velocidad increíblemente rápidas en comparación con los métodos actuales con mecánica clásica. (pp. 4-5) Por tanto, decidimos investigar acerca de estos métodos de computación mediante mecánica cuántica. Como primera instancia, expondremos las unidades básicas y características fundamentales de la computación cuántica.

\begin{thebibliography}{X}
\bibitem{etiqueta} \textsc{Autor, A.} (año). \textit{Título del libro.} Lugar: Editorial
\bibitem{arce} \textsc{Arce, C., Castillo, W., González, J.} (2003). \textit{Álgebra Lineal.} Lugar: Editorial
\bibitem{herken} \textsc{Herken, R. (Ed.)} (1988). \textit{The Universal Turing Machine. A Half-Century Survey.} (E. Arias, Trad.) Oxford University Press
\bibitem{moore} \textsc{Moore, G.} (1965). Cramming more components onto integrated circuits. \textit{Electronics.} Vol 3., No. 8.
\bibitem{nielsen} \textsc{Nielsen, M., Chuang, I.} (2010). \textit{Quantum Computation and Quantum Information.} (E. Arias, Trad.) New York: Cambridge University Press
\bibitem{shankar} \textsc{Shankar, R.} (1994). \textit{Principles of Quantum Mechanics.} (E. Arias, Trad.) New York: Plenum Press
\bibitem{turing} \textsc{Turing, A.} (1936). \textit{ON COMPUTABLE NUMBERS, WITH AN APPLICATION TO
THE ENTSCHEIDUNGSPROBLEM.} (E. Arias, Trad.) Recuperado de http://classes.soe.ucsc.edu/cmps210/Winter11/Papers/turing-1936.pdf
\bibitem{neumann} \textsc{Von Neumann, J.} (1945). \textit{First Draft of a Report on the EDVAC} University of Pennsylvania. Recuperado de http://www.virtualtravelog.net/wp/wp-content/media/2003-08-TheFirstDraft.pdf
\end{thebibliography}

\end{document}
